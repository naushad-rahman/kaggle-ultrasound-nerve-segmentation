## Kaggle Ultrasound Nerve Segmentation competition

The task in this competition is to segment a collection of nerves called
the Brachial Plexus (BP) in ultrasound images. You are provided with a
large training set of images where the nerve has been manually annotated
by humans. Annotators were trained by experts and instructed to annotate
images where they felt confident about the existence of the BP landmark.

The model was build based on the U-Net: Convolutional Networks for
Biomedical Image Segmentation
[U-Net](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/)

A diagram of U-Net Architecture:
![U-Net Architecture](./u-net-architecture.png)

I've used images provided by Kaggle's Team 
[Data set](https://www.kaggle.com/c/ultrasound-nerve-segmentation/data).

### Before training i did image pre-processing. There were a few steps involved:

All imaged are located in `raw/` folder.
```
    raw/..
      test/..
      train/..  
    
    **/train/** contains the training set images, named according to
    subject_imageNum.tif. Every image with the same subject number comes
    from the same person. This folder also includes binary mask images
    showing the BP segmentation.
    
    **/test/** contains the test set images, named according to imageNum.tif.
    You must predict the BP segmentation for these images and are not
    provided a subject number. There is no overlap between the subjects in
    the training and test sets.
    
    **train_masks.csv** gives the training image masks in run-length encoded
    format. This is provided as a convenience to demonstrate how to turn
    image masks into encoded text values for submission.
    
    **sample_submission.csv** shows the correct submission file format.
```
1. I've loaded image data into `imgs_train.npy`
2. I've loaded image mask data into `imgs_mask_train.npy`
3. Same for test images from `raw/test/`
4. `*.npy` are in `.gitignore` as they are too big and can be easily generated by running `python image_processing.py`.
5. The images are not pre-processed, resizing to 64 x 80 was applied. Output images (masks) are scaled to `[0, 1]` interval.
To Pre-process images run `python image_processing.py`, implying that `train` and `test` data sets (*.tif) are located in `raw` folder.
Script will create four files:
```python
imgs_test.npy
imgs_mask_test.npy
imgs_train.npy
imgs_mask_train.npy
```

### Model training

Model was trained on `4508` images and 
```python
Learn_Rate = 1e-5
Padding = 'same'
Activation_Function = 'relu'
Kernel_Size = (3, 3)
Epochs = 20
Strides = (1, 1)
```
The best performance was reached while using Adam Optimized with Learning Rate of `1e-5`.
It took about `48 seconds` per epoch on `g3.x4 GPU` in AWS. Model can be trained locally, it took me `2698s` to run one epoch on MacBook Pro.
To run a model, run `python train.py`. All setting are pulled into constants for easier access for modification in `model.py`.

### Submission
 To submit a results I ran a script `python submit.py` that will generate a `submission.csv` that has two columns `(image, pixels)`. Generate by reading and analyzing data from previously generated `imgs_mask_test.npy`.